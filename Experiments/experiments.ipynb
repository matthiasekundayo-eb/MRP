{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matthias/.pyenv/versions/3.8.10/lib/python3.8/site-packages/pandas/compat/__init__.py:124: UserWarning: Could not import the lzma module. Your installed Python is incomplete. Attempting to use lzma compression will result in a RuntimeError.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model, svm\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler, normalize\n",
    "from sklearn.metrics import mean_squared_log_error, mean_squared_error\n",
    "import scipy.stats\n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost\n",
    "import seaborn as sns\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "import tqdm\n",
    "from sklearn.experimental import enable_halving_search_cv\n",
    "from sklearn.model_selection import GridSearchCV, HalvingGridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "import warnings # supress warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_training_dataset = pd.read_csv('../EDA/train.csv')\n",
    "raw_test_dataset = pd.read_csv('../EDA/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_id = np.array(raw_test_dataset['Id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_features = ['MSSubClass',\n",
    "                    'LotFrontage',\n",
    "                    'LotArea',\n",
    "                    'OverallQual',\n",
    "                    'OverallCond',\n",
    "                    'YearBuilt',\n",
    "                    'YearRemodAdd',\n",
    "                    'MasVnrArea',\n",
    "                    'BsmtFinSF1',\n",
    "                    'BsmtFinSF2',\n",
    "                    'BsmtUnfSF',\n",
    "                    'TotalBsmtSF',\n",
    "                    '1stFlrSF',\n",
    "                    '2ndFlrSF',\n",
    "                    'LowQualFinSF',\n",
    "                    'GrLivArea',\n",
    "                    'BsmtFullBath',\n",
    "                    'BsmtHalfBath',\n",
    "                    'FullBath',\n",
    "                    'HalfBath',\n",
    "                    'BedroomAbvGr',\n",
    "                    'KitchenAbvGr',\n",
    "                    'TotRmsAbvGrd',\n",
    "                    'Fireplaces',\n",
    "                    'GarageYrBlt',\n",
    "                    'GarageCars',\n",
    "                    'GarageArea',\n",
    "                    'WoodDeckSF',\n",
    "                    'OpenPorchSF',\n",
    "                    'EnclosedPorch',\n",
    "                    '3SsnPorch',\n",
    "                    'ScreenPorch',\n",
    "                    'PoolArea',\n",
    "                    'MiscVal',\n",
    "                    'MoSold',\n",
    "                    'YrSold',]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = [col for col in raw_training_dataset.columns if col not in numerical_features+['Id', 'SalePrice']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Experiment 1 - Features with correlation of 0.5 and above with p-value of less than or equal to 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relevant Numerical Features: ['OverallQual', 'YearBuilt', 'YearRemodAdd', 'TotalBsmtSF', '1stFlrSF', 'GrLivArea', 'FullBath', 'TotRmsAbvGrd', 'GarageCars', 'GarageArea']\n",
      "Relevant Categorical Features: ['ExterQual_TA', 'BsmtQual_Ex', 'KitchenQual_Ex', 'KitchenQual_TA']\n"
     ]
    }
   ],
   "source": [
    "correlation_dict = {}\n",
    "for col in numerical_features:\n",
    "    # print(f\"Correlation between {col} and SalesPrice = {scipy.stats.pearsonr(raw_training_dataset[col], raw_training_dataset['SalePrice'])}\")\n",
    "    raw_training_dataset[col] = raw_training_dataset[col].fillna(0)\n",
    "    raw_test_dataset[col] = raw_test_dataset[col].fillna(0) \n",
    "    correlation_dict[col] = [round(scipy.stats.pearsonr(raw_training_dataset[col], raw_training_dataset['SalePrice'])[0], 5), \n",
    "                            round(scipy.stats.pearsonr(raw_training_dataset[col], raw_training_dataset['SalePrice'])[1], 5)]\n",
    "\n",
    "# correlation_dict\n",
    "relevant_numerical_features = []\n",
    "for key, value in correlation_dict.items():\n",
    "    # picking only columns that have absolute correlation >= 0.5 and with a p-value of < 0.05\n",
    "    if abs(correlation_dict[key][0]) >= 0.5 and correlation_dict[key][1] <= 0.05:\n",
    "        relevant_numerical_features.append(key)\n",
    "\n",
    "print(f\"Relevant Numerical Features: {relevant_numerical_features}\")\n",
    "\n",
    "\n",
    "correlation_dict_categorical = {}\n",
    "for col in categorical_features:\n",
    "    one_hot_df = pd.get_dummies(raw_training_dataset[col])\n",
    "    one_hot_col_names = one_hot_df.columns\n",
    "    for ohc in one_hot_col_names:\n",
    "        correlation_dict_categorical[f'{col}_{ohc}'] = [round(scipy.stats.pearsonr(one_hot_df[ohc], raw_training_dataset['SalePrice'])[0], 5), \n",
    "                                            round(scipy.stats.pearsonr(one_hot_df[ohc], raw_training_dataset['SalePrice'])[1], 5)]\n",
    "\n",
    "# correlation_dict_categorical\n",
    "relevant_categorical_features = []\n",
    "for key in correlation_dict_categorical.keys():\n",
    "    # picking only columns that have absolute correlation >= 0.5 and with a p-value of <= 0.05\n",
    "    if abs(correlation_dict_categorical[key][0]) >= 0.5 and correlation_dict_categorical[key][1] <= 0.05:\n",
    "        relevant_categorical_features.append(key)\n",
    "\n",
    "\n",
    "print(f\"Relevant Categorical Features: {relevant_categorical_features}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_df = pd.get_dummies(raw_training_dataset[[c.split(\"_\")[0] for c in relevant_categorical_features]])\n",
    "\n",
    "normalized_df = raw_training_dataset[relevant_numerical_features]\n",
    "n_rows = normalized_df.shape[0]\n",
    "n_cols = normalized_df.shape[1]\n",
    "for i in range(n_cols):\n",
    "    normalized_df.iloc[:,i] = normalize([normalized_df.iloc[:,i]]).reshape(-1,1)\n",
    "\n",
    "normalized_onehot_df = pd.concat([normalized_df, one_hot_df], axis=1)\n",
    "\n",
    "X = normalized_onehot_df.values\n",
    "y = raw_training_dataset.iloc[:,-1:].values\n",
    "\n",
    "normalized_test_df = raw_test_dataset[relevant_numerical_features]\n",
    "# normalized_test_df.fillna(0)\n",
    "n_cols = normalized_test_df.shape[1]\n",
    "for i in range(n_cols):\n",
    "    normalized_test_df.iloc[:,i] = normalize([normalized_test_df.iloc[:,i]]).reshape(-1,1)\n",
    "\n",
    "one_hot_df_test = pd.get_dummies(raw_test_dataset[[c.split(\"_\")[0] for c in relevant_categorical_features]])\n",
    "\n",
    "normalized_onehot_df_test = pd.concat([normalized_test_df, one_hot_df_test], axis=1)\n",
    "\n",
    "x_test = normalized_onehot_df_test.values\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=41)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear model - mean_squared_error: 809538862.02\n",
      "Linear model - mean_squared_log_error: 0.026489359851081886\n",
      "SVM - mean_squared_error: 5730838074.66\n",
      "SVM - mean_squared_log_error: 0.14523856411674407\n",
      "XGBoost - mean_squared_error: 979621780.47\n",
      "XGBoost - mean_squared_log_error: 0.028150605417908606\n",
      "MLP - mean_squared_error: 939569497.42\n",
      "MLP - mean_squared_log_error: 0.030504611776193232\n"
     ]
    }
   ],
   "source": [
    "# Linear Regression\n",
    "linear_reg_model = linear_model.LinearRegression()\n",
    "linear_reg_model.fit(x_train, y_train)\n",
    "linear_pred = linear_reg_model.predict(x_val)\n",
    "\n",
    "print(f'Linear model - mean_squared_error: {round(mean_squared_error(y_val, linear_pred),2)}')\n",
    "print(f'Linear model - mean_squared_log_error: {mean_squared_log_error(y_val, linear_pred)}')\n",
    "\n",
    "\n",
    "# SVM\n",
    "svm_model = svm.SVR()\n",
    "svm_model.fit(x_train, y_train.reshape(-1,1))\n",
    "svm_pred = svm_model.predict(x_val)\n",
    "\n",
    "print(f'SVM - mean_squared_error: {round(mean_squared_error(y_val, svm_pred),2)}')\n",
    "print(f'SVM - mean_squared_log_error: {mean_squared_log_error(y_val, svm_pred)}')\n",
    "\n",
    "\n",
    "# XGBoost\n",
    "xgboost_model = xgboost.XGBRegressor()\n",
    "xgboost_model.fit(x_train, y_train)\n",
    "xgb_pred = xgboost_model.predict(x_val)\n",
    "\n",
    "print(f'XGBoost - mean_squared_error: {round(mean_squared_error(y_val, xgb_pred),2)}')\n",
    "print(f'XGBoost - mean_squared_log_error: {mean_squared_log_error(y_val, xgb_pred)}')\n",
    "\n",
    "\n",
    "# MLP\n",
    "mlp_regressor_model = MLPRegressor(hidden_layer_sizes=100, activation='relu', solver='adam', max_iter=50000)\n",
    "mlp_regressor_model.fit(x_train, y_train.reshape(-1,1))\n",
    "mlp_pred = mlp_regressor_model.predict(x_val)\n",
    "print(f'MLP - mean_squared_error: {round(mean_squared_error(y_val.reshape(-1,1), mlp_pred),2)}')\n",
    "print(f'MLP - mean_squared_log_error: {mean_squared_log_error(y_val.reshape(-1,1), mlp_pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Experiment 2 - Features with correlation of 0.7 and above with p-value of less than or equal to 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relevant Numerical Features: ['OverallQual', 'GrLivArea']\n",
      "Relevant Categorical Features: []\n"
     ]
    }
   ],
   "source": [
    "correlation_dict = {}\n",
    "for col in numerical_features:\n",
    "    # print(f\"Correlation between {col} and SalesPrice = {scipy.stats.pearsonr(raw_training_dataset[col], raw_training_dataset['SalePrice'])}\")\n",
    "    raw_training_dataset[col] = raw_training_dataset[col].fillna(0)\n",
    "    raw_test_dataset[col] = raw_test_dataset[col].fillna(0) \n",
    "    correlation_dict[col] = [round(scipy.stats.pearsonr(raw_training_dataset[col], raw_training_dataset['SalePrice'])[0], 5), \n",
    "                            round(scipy.stats.pearsonr(raw_training_dataset[col], raw_training_dataset['SalePrice'])[1], 5)]\n",
    "\n",
    "# correlation_dict\n",
    "relevant_numerical_features = []\n",
    "for key, value in correlation_dict.items():\n",
    "    # picking only columns that have absolute correlation >= 0.7 and with a p-value of < 0.05\n",
    "    if abs(correlation_dict[key][0]) >= 0.7 and correlation_dict[key][1] <= 0.05:\n",
    "        relevant_numerical_features.append(key)\n",
    "\n",
    "print(f\"Relevant Numerical Features: {relevant_numerical_features}\")\n",
    "\n",
    "\n",
    "correlation_dict_categorical = {}\n",
    "for col in categorical_features:\n",
    "    one_hot_df = pd.get_dummies(raw_training_dataset[col])\n",
    "    one_hot_col_names = one_hot_df.columns\n",
    "    for ohc in one_hot_col_names:\n",
    "        correlation_dict_categorical[f'{col}_{ohc}'] = [round(scipy.stats.pearsonr(one_hot_df[ohc], raw_training_dataset['SalePrice'])[0], 5), \n",
    "                                            round(scipy.stats.pearsonr(one_hot_df[ohc], raw_training_dataset['SalePrice'])[1], 5)]\n",
    "\n",
    "# correlation_dict_categorical\n",
    "relevant_categorical_features = []\n",
    "for key in correlation_dict_categorical.keys():\n",
    "    # picking only columns that have absolute correlation >= 0.7 and with a p-value of <= 0.05\n",
    "    if abs(correlation_dict_categorical[key][0]) >= 0.7 and correlation_dict_categorical[key][1] <= 0.05:\n",
    "        relevant_categorical_features.append(key)\n",
    "\n",
    "\n",
    "print(f\"Relevant Categorical Features: {relevant_categorical_features}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_df = raw_training_dataset[relevant_numerical_features]\n",
    "n_rows = normalized_df.shape[0]\n",
    "n_cols = normalized_df.shape[1]\n",
    "for i in range(n_cols):\n",
    "    normalized_df.iloc[:,i] = normalize([normalized_df.iloc[:,i]]).reshape(-1,1)\n",
    "\n",
    "X = normalized_df.values\n",
    "y = raw_training_dataset.iloc[:,-1:].values\n",
    "\n",
    "normalized_test_df = raw_test_dataset[relevant_numerical_features]\n",
    "n_cols = normalized_test_df.shape[1]\n",
    "for i in range(n_cols):\n",
    "    normalized_test_df.iloc[:,i] = normalize([normalized_test_df.iloc[:,i]]).reshape(-1,1)\n",
    "\n",
    "x_test = normalized_test_df.values\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=41)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear model - mean_squared_error: 1254167558.26\n",
      "Linear model - mean_squared_log_error: 0.042042309837848\n",
      "SVM - mean_squared_error: 5733793982.48\n",
      "SVM - mean_squared_log_error: 0.1452314508925064\n",
      "XGBoost - mean_squared_error: 1246801872.71\n",
      "XGBoost - mean_squared_log_error: 0.039042448486032263\n",
      "MLP - mean_squared_error: 3651351031.52\n",
      "MLP - mean_squared_log_error: 0.10205991350076908\n"
     ]
    }
   ],
   "source": [
    "# Linear Regression\n",
    "linear_reg_model = linear_model.LinearRegression()\n",
    "linear_reg_model.fit(x_train, y_train)\n",
    "linear_pred = linear_reg_model.predict(x_val)\n",
    "\n",
    "print(f'Linear model - mean_squared_error: {round(mean_squared_error(y_val, linear_pred),2)}')\n",
    "print(f'Linear model - mean_squared_log_error: {mean_squared_log_error(y_val, linear_pred)}')\n",
    "\n",
    "\n",
    "# SVM\n",
    "svm_model = svm.SVR()\n",
    "svm_model.fit(x_train, y_train.reshape(-1,1))\n",
    "svm_pred = svm_model.predict(x_val)\n",
    "\n",
    "print(f'SVM - mean_squared_error: {round(mean_squared_error(y_val, svm_pred),2)}')\n",
    "print(f'SVM - mean_squared_log_error: {mean_squared_log_error(y_val, svm_pred)}')\n",
    "\n",
    "\n",
    "# XGBoost\n",
    "xgboost_model = xgboost.XGBRegressor()\n",
    "xgboost_model.fit(x_train, y_train)\n",
    "xgb_pred = xgboost_model.predict(x_val)\n",
    "\n",
    "print(f'XGBoost - mean_squared_error: {round(mean_squared_error(y_val, xgb_pred),2)}')\n",
    "print(f'XGBoost - mean_squared_log_error: {mean_squared_log_error(y_val, xgb_pred)}')\n",
    "\n",
    "\n",
    "# MLP\n",
    "mlp_regressor_model = MLPRegressor(hidden_layer_sizes=100, activation='relu', solver='adam', max_iter=50000)\n",
    "mlp_regressor_model.fit(x_train, y_train.reshape(-1,1))\n",
    "mlp_pred = mlp_regressor_model.predict(x_val)\n",
    "print(f'MLP - mean_squared_error: {round(mean_squared_error(y_val.reshape(-1,1), mlp_pred),2)}')\n",
    "print(f'MLP - mean_squared_log_error: {mean_squared_log_error(y_val.reshape(-1,1), mlp_pred)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Experiment 3 - Numerical features with correlation of 0.5 and above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relevant Numerical Features: ['OverallQual', 'YearBuilt', 'YearRemodAdd', 'TotalBsmtSF', '1stFlrSF', 'GrLivArea', 'FullBath', 'TotRmsAbvGrd', 'GarageCars', 'GarageArea']\n"
     ]
    }
   ],
   "source": [
    "correlation_dict = {}\n",
    "for col in numerical_features:\n",
    "    # print(f\"Correlation between {col} and SalesPrice = {scipy.stats.pearsonr(raw_training_dataset[col], raw_training_dataset['SalePrice'])}\")\n",
    "    raw_training_dataset[col] = raw_training_dataset[col].fillna(0)\n",
    "    raw_test_dataset[col] = raw_test_dataset[col].fillna(0) \n",
    "    correlation_dict[col] = [round(scipy.stats.pearsonr(raw_training_dataset[col], raw_training_dataset['SalePrice'])[0], 5), \n",
    "                            round(scipy.stats.pearsonr(raw_training_dataset[col], raw_training_dataset['SalePrice'])[1], 5)]\n",
    "\n",
    "# correlation_dict\n",
    "relevant_numerical_features = []\n",
    "for key, value in correlation_dict.items():\n",
    "    # picking only columns that have absolute correlation >= 0.5 and with a p-value of < 0.05\n",
    "    if abs(correlation_dict[key][0]) >= 0.5 and correlation_dict[key][1] <= 0.05:\n",
    "        relevant_numerical_features.append(key)\n",
    "\n",
    "print(f\"Relevant Numerical Features: {relevant_numerical_features}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_df = raw_training_dataset[relevant_numerical_features]\n",
    "n_rows = normalized_df.shape[0]\n",
    "n_cols = normalized_df.shape[1]\n",
    "for i in range(n_cols):\n",
    "    normalized_df.iloc[:,i] = normalize([normalized_df.iloc[:,i]]).reshape(-1,1)\n",
    "\n",
    "X = normalized_df.values\n",
    "y = raw_training_dataset.iloc[:,-1:].values\n",
    "\n",
    "normalized_test_df = raw_test_dataset[relevant_numerical_features]\n",
    "n_cols = normalized_test_df.shape[1]\n",
    "for i in range(n_cols):\n",
    "    normalized_test_df.iloc[:,i] = normalize([normalized_test_df.iloc[:,i]]).reshape(-1,1)\n",
    "\n",
    "x_test = normalized_test_df.values\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=41)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear model - mean_squared_error: 884673636.14\n",
      "Linear model - mean_squared_log_error: 0.030812049124109512\n",
      "SVM - mean_squared_error: 5738562507.13\n",
      "SVM - mean_squared_log_error: 0.14541297117259308\n",
      "XGBoost - mean_squared_error: 929663020.91\n",
      "XGBoost - mean_squared_log_error: 0.027251699300227403\n",
      "MLP - mean_squared_error: 1267751422.45\n",
      "MLP - mean_squared_log_error: 0.04710244907350764\n"
     ]
    }
   ],
   "source": [
    "# Linear Regression\n",
    "linear_reg_model = linear_model.LinearRegression()\n",
    "linear_reg_model.fit(x_train, y_train)\n",
    "linear_pred = linear_reg_model.predict(x_val)\n",
    "\n",
    "print(f'Linear model - mean_squared_error: {round(mean_squared_error(y_val, linear_pred),2)}')\n",
    "print(f'Linear model - mean_squared_log_error: {mean_squared_log_error(y_val, linear_pred)}')\n",
    "\n",
    "\n",
    "# SVM\n",
    "svm_model = svm.SVR()\n",
    "svm_model.fit(x_train, y_train.reshape(-1,1))\n",
    "svm_pred = svm_model.predict(x_val)\n",
    "\n",
    "print(f'SVM - mean_squared_error: {round(mean_squared_error(y_val, svm_pred),2)}')\n",
    "print(f'SVM - mean_squared_log_error: {mean_squared_log_error(y_val, svm_pred)}')\n",
    "\n",
    "\n",
    "# XGBoost\n",
    "xgboost_model = xgboost.XGBRegressor()\n",
    "xgboost_model.fit(x_train, y_train)\n",
    "xgb_pred = xgboost_model.predict(x_val)\n",
    "\n",
    "print(f'XGBoost - mean_squared_error: {round(mean_squared_error(y_val, xgb_pred),2)}')\n",
    "print(f'XGBoost - mean_squared_log_error: {mean_squared_log_error(y_val, xgb_pred)}')\n",
    "\n",
    "\n",
    "# MLP\n",
    "mlp_regressor_model = MLPRegressor(hidden_layer_sizes=100, activation='relu', solver='adam', max_iter=50000)\n",
    "mlp_regressor_model.fit(x_train, y_train.reshape(-1,1))\n",
    "mlp_pred = mlp_regressor_model.predict(x_val)\n",
    "print(f'MLP - mean_squared_error: {round(mean_squared_error(y_val.reshape(-1,1), mlp_pred),2)}')\n",
    "print(f'MLP - mean_squared_log_error: {mean_squared_log_error(y_val.reshape(-1,1), mlp_pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('3.8.10')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4197339e453f09211c34e4d2bfbab4ce6556e3c49a876365310778e57a9a0e58"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
