{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model, svm\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler, normalize\n",
    "from sklearn.metrics import mean_squared_log_error, mean_squared_error\n",
    "import scipy.stats\n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost\n",
    "import seaborn as sns\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "import tqdm\n",
    "from sklearn.experimental import enable_halving_search_cv\n",
    "from sklearn.model_selection import GridSearchCV, HalvingGridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import optuna\n",
    "\n",
    "import warnings # supress warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_training_dataset = pd.read_csv('../EDA/train.csv')\n",
    "raw_test_dataset = pd.read_csv('../EDA/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_id = np.array(raw_test_dataset['Id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_features = ['MSSubClass',\n",
    "                    'LotFrontage',\n",
    "                    'LotArea',\n",
    "                    'OverallQual',\n",
    "                    'OverallCond',\n",
    "                    'YearBuilt',\n",
    "                    'YearRemodAdd',\n",
    "                    'MasVnrArea',\n",
    "                    'BsmtFinSF1',\n",
    "                    'BsmtFinSF2',\n",
    "                    'BsmtUnfSF',\n",
    "                    'TotalBsmtSF',\n",
    "                    '1stFlrSF',\n",
    "                    '2ndFlrSF',\n",
    "                    'LowQualFinSF',\n",
    "                    'GrLivArea',\n",
    "                    'BsmtFullBath',\n",
    "                    'BsmtHalfBath',\n",
    "                    'FullBath',\n",
    "                    'HalfBath',\n",
    "                    'BedroomAbvGr',\n",
    "                    'KitchenAbvGr',\n",
    "                    'TotRmsAbvGrd',\n",
    "                    'Fireplaces',\n",
    "                    'GarageYrBlt',\n",
    "                    'GarageCars',\n",
    "                    'GarageArea',\n",
    "                    'WoodDeckSF',\n",
    "                    'OpenPorchSF',\n",
    "                    'EnclosedPorch',\n",
    "                    '3SsnPorch',\n",
    "                    'ScreenPorch',\n",
    "                    'PoolArea',\n",
    "                    'MiscVal',\n",
    "                    'MoSold',\n",
    "                    'YrSold',]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = [col for col in raw_training_dataset.columns if col not in numerical_features+['Id', 'SalePrice']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relevant Numerical Features: ['OverallQual', 'YearBuilt', 'YearRemodAdd', 'TotalBsmtSF', '1stFlrSF', 'GrLivArea', 'FullBath', 'TotRmsAbvGrd', 'GarageCars', 'GarageArea']\n",
      "Relevant Categorical Features: ['ExterQual_TA', 'BsmtQual_Ex', 'KitchenQual_Ex', 'KitchenQual_TA']\n"
     ]
    }
   ],
   "source": [
    "correlation_dict = {}\n",
    "for col in numerical_features:\n",
    "    # print(f\"Correlation between {col} and SalesPrice = {scipy.stats.pearsonr(raw_training_dataset[col], raw_training_dataset['SalePrice'])}\")\n",
    "    raw_training_dataset[col] = raw_training_dataset[col].fillna(0)\n",
    "    raw_test_dataset[col] = raw_test_dataset[col].fillna(0) \n",
    "    correlation_dict[col] = [round(scipy.stats.pearsonr(raw_training_dataset[col], raw_training_dataset['SalePrice'])[0], 5), \n",
    "                            round(scipy.stats.pearsonr(raw_training_dataset[col], raw_training_dataset['SalePrice'])[1], 5)]\n",
    "\n",
    "# correlation_dict\n",
    "relevant_numerical_features = []\n",
    "for key, value in correlation_dict.items():\n",
    "    # picking only columns that have absolute correlation >= 0.5 and with a p-value of < 0.05\n",
    "    if abs(correlation_dict[key][0]) >= 0.5 and correlation_dict[key][1] <= 0.05:\n",
    "        relevant_numerical_features.append(key)\n",
    "\n",
    "print(f\"Relevant Numerical Features: {relevant_numerical_features}\")\n",
    "\n",
    "\n",
    "correlation_dict_categorical = {}\n",
    "for col in categorical_features:\n",
    "    one_hot_df = pd.get_dummies(raw_training_dataset[col])\n",
    "    one_hot_col_names = one_hot_df.columns\n",
    "    for ohc in one_hot_col_names:\n",
    "        correlation_dict_categorical[f'{col}_{ohc}'] = [round(scipy.stats.pearsonr(one_hot_df[ohc], raw_training_dataset['SalePrice'])[0], 5), \n",
    "                                            round(scipy.stats.pearsonr(one_hot_df[ohc], raw_training_dataset['SalePrice'])[1], 5)]\n",
    "\n",
    "# correlation_dict_categorical\n",
    "relevant_categorical_features = []\n",
    "for key in correlation_dict_categorical.keys():\n",
    "    # picking only columns that have absolute correlation >= 0.5 and with a p-value of <= 0.05\n",
    "    if abs(correlation_dict_categorical[key][0]) >= 0.5 and correlation_dict_categorical[key][1] <= 0.05:\n",
    "        relevant_categorical_features.append(key)\n",
    "\n",
    "\n",
    "print(f\"Relevant Categorical Features: {relevant_categorical_features}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_df = pd.get_dummies(raw_training_dataset[[c.split(\"_\")[0] for c in relevant_categorical_features]])\n",
    "\n",
    "normalized_df = raw_training_dataset[relevant_numerical_features]\n",
    "n_rows = normalized_df.shape[0]\n",
    "n_cols = normalized_df.shape[1]\n",
    "for i in range(n_cols):\n",
    "    normalized_df.iloc[:,i] = normalize([normalized_df.iloc[:,i]]).reshape(-1,1)\n",
    "\n",
    "normalized_onehot_df = pd.concat([normalized_df, one_hot_df], axis=1)\n",
    "\n",
    "X = normalized_onehot_df.values\n",
    "y = raw_training_dataset.iloc[:,-1:].values\n",
    "\n",
    "normalized_test_df = raw_test_dataset[relevant_numerical_features]\n",
    "# normalized_test_df.fillna(0)\n",
    "n_cols = normalized_test_df.shape[1]\n",
    "for i in range(n_cols):\n",
    "    normalized_test_df.iloc[:,i] = normalize([normalized_test_df.iloc[:,i]]).reshape(-1,1)\n",
    "\n",
    "one_hot_df_test = pd.get_dummies(raw_test_dataset[[c.split(\"_\")[0] for c in relevant_categorical_features]])\n",
    "\n",
    "normalized_onehot_df_test = pd.concat([normalized_test_df, one_hot_df_test], axis=1)\n",
    "\n",
    "x_test = normalized_onehot_df_test.values\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=41)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def algorithm_objective(trial):\n",
    "   \n",
    "    x_train, x_val, y_train, y_val = train_test_split(X, y, train_size = 0.1, random_state=41)\n",
    "    param = {\n",
    "        'lambda': trial.suggest_float('lambda', 1e-3, 10.0),\n",
    "        'alpha': trial.suggest_float('alpha', 1e-3, 10.0),\n",
    "        'colsample_bytree': trial.suggest_categorical('colsample_bytree', [0.3,0.4,0.5,0.6,0.7,0.8,0.9, 1.0]),\n",
    "        'subsample': trial.suggest_categorical('subsample', [0.4,0.5,0.6,0.7,0.8,1.0]),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 1e-3, 1e-1),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 1, 2000),\n",
    "        'max_depth': trial.suggest_int('max_depth', 5,100),\n",
    "        'random_state': 41,\n",
    "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 300),\n",
    "    }\n",
    "    model = xgboost.XGBRegressor(**param, eval_metric= 'rmsle')  \n",
    "    model.fit(x_train,y_train,eval_set=[(x_train, y_train), (x_val, y_val)],verbose=False)\n",
    "    predictions = model.predict(x_val)\n",
    "    validations = cross_val_score(model, x_val, y_val, cv = 5, n_jobs = -1,scoring = 'neg_mean_squared_log_error')\n",
    "    return np.mean(validations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(algorithm_objective, n_trials=10000)\n",
    "print('Number of finished trials:', len(study.trials))\n",
    "print('Best trial:', study.best_trial.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_param = {'lambda': 8.821073920585857,\n",
    "                'alpha': 8.612310788986797,\n",
    "                'colsample_bytree': 0.5,\n",
    "                'subsample': 0.4,\n",
    "                'learning_rate': 0.005918228156202181,\n",
    "                'n_estimators': 1479,\n",
    "                'max_depth': 6,\n",
    "                'min_child_weight': 1}\n",
    "\n",
    "xgboost_model = xgboost.XGBRegressor(eval_metric= 'rmse', **best_param)\n",
    "xgboost_model.fit(X, y)\n",
    "pred_test = xgboost_model.predict(x_test)\n",
    "submission_df = pd.DataFrame(columns=['Id','SalePrice'])\n",
    "submission_df['Id'] = submission_id\n",
    "submission_df['SalePrice'] = pred_test\n",
    "submission_df\n",
    "submission_df.to_csv('submission.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('3.8.10')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4197339e453f09211c34e4d2bfbab4ce6556e3c49a876365310778e57a9a0e58"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
